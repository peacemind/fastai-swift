{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai-les14-03-minibatch-training.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adlu-A15_Yo4",
        "colab_type": "text"
      },
      "source": [
        "Minibatch training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRlD4utdPuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "0f6aeea3-ff03-4a6f-daa4-2bab2eae9bd0"
      },
      "source": [
        "%install-location $cwd/swift-install\n",
        "%install '.package(path: \"$cwd/FastaiNotebook_02a_why_sqrt5\")' FastaiNotebook_02a_why_sqrt5"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages:\n",
            "\t.package(path: \"/content/FastaiNotebook_02a_why_sqrt5\")\n",
            "\t\tFastaiNotebook_02a_why_sqrt5\n",
            "With SwiftPM flags: []\n",
            "Working in: /tmp/tmp6a9dhkh4/swift-install\n",
            "[1/2] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
            "[2/3] Merging module jupyterInstalledPackages\n",
            "Initializing Swift...\n",
            "Installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5DM-gRu_czK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "//export\n",
        "import Path\n",
        "import TensorFlow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guY2jpRl_kKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import FastaiNotebook_02a_why_sqrt5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-urWVm8X_pkg",
        "colab_type": "text"
      },
      "source": [
        "Our labels will be integeres from now on, so to go with our TF abbreviation, we introduce TI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0M_EsW5_myr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// export\n",
        "public typealias TI = Tensor<Int32>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1VcmQJ3_vLx",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Data\n",
        "\n",
        "We gather the MNIST data like in the previous notebooks.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-saM2qV_sSw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "758595f4-c1c4-44ab-e4da-b264d36038f0"
      },
      "source": [
        "var (xTrain,yTrain,xValid,yValid) = loadMNIST(path: Path.home/\".fastai\"/\"data\"/\"mnist_tst\", flat: true)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-17 23:52:32.528218: W tensorflow/core/framework/allocator.cc:107] Allocation of 188160000 exceeds 10% of system memory.\n",
            "2019-08-17 23:52:32.661992: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "2019-08-17 23:52:32.673864: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2019-08-17 23:52:32.674203: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2baec40 executing computations on platform Host. Devices:\n",
            "2019-08-17 23:52:32.674232: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-17 23:52:32.801750: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-17 23:52:32.807871: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-17 23:52:32.808286: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \n",
            "name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59\n",
            "pciBusID: 0000:00:04.0\n",
            "2019-08-17 23:52:32.808308: I tensorflow/stream_executor/platform/default/dlopen_checker_stub.cc:25] GPU libraries are statically linked, skip dlopen check.\n",
            "2019-08-17 23:52:32.808368: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-17 23:52:32.808722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-17 23:52:32.809025: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1763] Adding visible gpu devices: 0\n",
            "2019-08-17 23:52:33.380003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1181] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2019-08-17 23:52:33.380058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1187]      0 \n",
            "2019-08-17 23:52:33.380073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1200] 0:   N \n",
            "2019-08-17 23:52:33.380256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-17 23:52:33.380644: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-17 23:52:33.380981: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2019-08-17 23:52:33.381338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1326] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 12374 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2019-08-17 23:52:33.383064: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24998d80 executing computations on platform CUDA. Devices:\n",
            "2019-08-17 23:52:33.383114: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIIV3i9z_yeh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let trainMean = xTrain.mean()\n",
        "let trainStd = xTrain.std()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVqVDnYq_9GY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xTrain = normalize(xTrain, mean: trainMean, std: trainStd)\n",
        "xValid = normalize(xValid, mean: trainMean, std: trainStd)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKEZcSV8AAjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d34308a5-8159-49ac-966e-c44ad80e0e3c"
      },
      "source": [
        "let (n,m) = (xTrain.shape[0],xTrain.shape[1])\n",
        "let c = yTrain.max().scalarized()+1\n",
        "print(n,m,c)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 784 10\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXM1lX6PAP1l",
        "colab_type": "text"
      },
      "source": [
        "We also define a simple model using our FADense layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8IUb4mPAOt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let nHid = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Uq0mKTMAV7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public struct MyModel: Layer {\n",
        "    public var layer1: FADense<Float>\n",
        "    public var layer2: FADense<Float>\n",
        "    \n",
        "    public init(nIn: Int, nHid: Int, nOut: Int){\n",
        "        layer1 = FADense(nIn, nHid, activation: relu)\n",
        "        layer2 = FADense(nHid, nOut)\n",
        "    }\n",
        "    \n",
        "    @differentiable\n",
        "    public func callAsFunction(_ input: TF) -> TF {\n",
        "        return input.sequenced(through: layer1, layer2)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8aKBrlMAkA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var model = MyModel(nIn: m, nHid: nHid, nOut: Int(c))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urZdfsHcBTa0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let pred = model(xTrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkrJKOo3Asbp",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Cross entropy loss\n",
        "\n",
        "Before we can train our model, we need to have a loss function. We saw how to write logSoftMax from scratch in PyTorch, but let's do it once in swift too.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kctHD-ppAqU9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func logSoftmax<Scalar>(_ activations: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
        "    let exped = exp(activations) \n",
        "    return log(exped / exped.sum(alongAxes: -1))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9F76dgpBGVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let smPred = logSoftmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_V3ixVyBJp0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc5c2cf4-2edf-4c7a-9ee1-6b7a47779714"
      },
      "source": [
        "yTrain[0..<3]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5, 0, 4]\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp7yksBGBkPs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "2be41abc-5d7e-44f0-e211-0df3370782be"
      },
      "source": [
        "(smPred[0][5],smPred[1][0],smPred[2][4])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "▿ 3 elements\n",
              "  - .0 : -2.49947\n",
              "  - .1 : -1.9931937\n",
              "  - .2 : -2.315899\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCRdv0B4BvFT",
        "colab_type": "text"
      },
      "source": [
        "There is no fancy indexing yet so we have to use gather to get the indices we want out of our softmaxed predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU2OLdoCBsxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func nll<Scalar>(_ input: Tensor<Scalar>, _ target :TI) -> Tensor<Scalar> \n",
        "    where Scalar:TensorFlowFloatingPoint{\n",
        "        let idx: TI = Raw.range(start: Tensor(0), limit: Tensor(numericCast(target.shape[0])), delta: Tensor(1))\n",
        "        let indices = Raw.concat(concatDim: Tensor(1), [idx.expandingShape(at: 1), target.expandingShape(at: 1)])\n",
        "        let losses = Raw.gatherNd(params: input, indices: indices)\n",
        "        return -losses.mean()\n",
        "    }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_YtrW3UB0KE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7bd6a1fd-572a-43fe-9152-27ba5f3f27e4"
      },
      "source": [
        "nll(smPred, yTrain)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.433661\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQS9xm0UCom4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9eda59a3-26fd-4ac0-836e-9eaec5faf8e5"
      },
      "source": [
        "time(repeating: 100){ let _ = nll(smPred, yTrain) }"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average: 1.34495376 ms,   min: 1.288027 ms,   max: 1.667748 ms\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCYTIzoZCtvg",
        "colab_type": "text"
      },
      "source": [
        "Simplify logSoftmax with log formulas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-2IL9OiCrch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func logSoftmax<Scalar>(_ activations: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
        "    return activations - log(exp(activations).sum(alongAxes: -1))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ot8JrEgQAs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let smPred = logSoftmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MUkaKtIQGB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05add864-f23e-4c9e-fc6a-2ba2ef5137d6"
      },
      "source": [
        "nll(smPred, yTrain)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.433661\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbhCGM4eQLL4",
        "colab_type": "text"
      },
      "source": [
        "We know use the LogSumExp trick"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KovJsSidQIlb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "a7eac204-3474-4889-8269-ca599ca84dfd"
      },
      "source": [
        "smPred.max(alongAxes: -1).shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "▿ [60000, 1]\n",
              "  ▿ dimensions : 2 elements\n",
              "    - 0 : 60000\n",
              "    - 1 : 1\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w_VuOBAQQij",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func logSumExp<Scalar>(_ x: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
        "    let m = x.max(alongAxes: -1)\n",
        "    return m + log(exp(x-m).sum(alongAxes: -1))\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-ti0qlQS3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func logSoftmax<Scalar>(_ activations: Tensor<Scalar>) -> Tensor<Scalar> where Scalar:TensorFlowFloatingPoint{\n",
        "    return activations - logSumExp(activations)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfFndmRqQVPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let smPred = logSoftmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGULUjCmQZVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "22b9a51f-64e8-495f-8bb0-ba71f4f18b75"
      },
      "source": [
        "nll(smPred, yTrain)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.433661\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeexTI8XQgJN",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "In S4TF nll loss is combined with softmax in:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvKKRqM5QbUb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fb1a6942-8b83-4e21-d8a8-7eecf284c710"
      },
      "source": [
        "let loss = softmaxCrossEntropy(logits: pred, labels: yTrain)\n",
        "loss"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.433661\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXmhGFXBQiel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "757a048a-43a5-4e96-a0df-fef4dfe61f5b"
      },
      "source": [
        "time(repeating: 100){ _ = nll(logSoftmax(pred), yTrain)}"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average: 2.21892531 ms,   min: 1.992839 ms,   max: 2.547516 ms\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amW3qd_bQkms",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "78c06730-3375-4438-ca53-3ca5999c660c"
      },
      "source": [
        "time(repeating: 100){ _ = softmaxCrossEntropy(logits: pred, labels: yTrain)}"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average: 0.5650015300000001 ms,   min: 0.493569 ms,   max: 0.726865 ms\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CN2zzuwdQsHr",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Basic training loop\n",
        "\n",
        "Basically the training loop repeats over the following steps:\n",
        "\n",
        "    get the output of the model on a batch of inputs\n",
        "    compare the output to the labels we have and compute a loss\n",
        "    calculate the gradients of the loss with respect to every parameter of the model\n",
        "    update said parameters with those gradients to make them a little bit better\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7inXD8kQpS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// export\n",
        "public func accuracy(_ output: TF, _ target: TI) -> TF{\n",
        "    let corrects = TF(output.argmax(squeezingAxis: 1) .== target)\n",
        "    return corrects.mean()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HpH2jcq4Q3m6",
        "colab_type": "text"
      },
      "source": [
        "We have a raw model for now, so it should be as good as random: 10% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWFSklvxQu46",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c7ba752-34d8-4fb4-ea26-3d786cb8826b"
      },
      "source": [
        "print(accuracy(pred, yTrain))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.11411667\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LX_YOPfMQ9wF",
        "colab_type": "text"
      },
      "source": [
        "So let's begin wit a minibatch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGUnygtMQ7hI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ec2d0f4c-656f-43f6-a8fb-8d23878ae36d"
      },
      "source": [
        "let bs=64                     // batch size\n",
        "let xb = xTrain[0..<bs]       // a mini-batch from x\n",
        "let preds = model(xb)         // predictions\n",
        "print(preds[0], preds.shape)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0.13336182,  -0.28004912,  0.092582434,    0.7030793,   -0.2503697, -0.013903353,\r\n",
            "  -0.10388616,  -0.12551375,   0.93135387,  -0.09813759] [64, 10]\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0P7GfaJRHTT",
        "colab_type": "text"
      },
      "source": [
        "Then we can compute a loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJnhkTveREWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let yb = yTrain[0..<bs]\n",
        "let loss = softmaxCrossEntropy(logits: preds, labels: yb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2kOysrSRK5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6140278f-7ade-4169-ad7f-0bde5ed2d96a"
      },
      "source": [
        "print(accuracy(preds, yb))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.109375\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG7lDIOpRNvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let lr:Float = 0.5   // learning rate\n",
        "let epochs = 1       // how many epochs to train for"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTt2NUy0RVU3",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "Then we can get our loss and gradients.\n",
        "\n",
        "Sometimes you'll see closures written this way (required if there is >1 statement in it).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwsX2SA_RTkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let (loss, grads) = model.valueWithGradient { model -> TF in\n",
        "    let preds = model(xb)\n",
        "    return softmaxCrossEntropy(logits: preds, labels: yb)\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKxmHyl7RZWR",
        "colab_type": "text"
      },
      "source": [
        "The full loop by hand would look like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MuQV7ySRXLw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in 1 ... epochs {\n",
        "    for i in 0 ..< (n-1)/bs {\n",
        "        let startIdx = i * bs\n",
        "        let endIdx = startIdx + bs\n",
        "        let xb = xTrain[startIdx..<endIdx]\n",
        "        let yb = yTrain[startIdx..<endIdx]\n",
        "        let (loss, grads) = model.valueWithGradient {\n",
        "            softmaxCrossEntropy(logits: $0(xb), labels: yb)\n",
        "        }\n",
        "        model.layer1.weight -= lr * grads.layer1.weight\n",
        "        model.layer1.bias   -= lr * grads.layer1.bias\n",
        "        model.layer2.weight -= lr * grads.layer2.weight\n",
        "        model.layer2.bias   -= lr * grads.layer2.bias\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R63VctFHRcdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "171ad6ed-2cbc-4bd2-e5b9-df2bbd0038ea"
      },
      "source": [
        "let preds = model(xValid)\n",
        "accuracy(preds, yValid)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.847\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yBz0FoL5Rk0j",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        ">80% in one epoch, not too bad!\n",
        "\n",
        "We use a shorcut: model.variables stands for model.allDifferentiableVariables in S4TF. It extracts from our model a new struct with only the trainable parameters. For instance if model is a BatchNorm layer, it has four tensor of floats: running mean, runing std, weights and bias. The corresponding model.variables only has the weights and bias tensors.\n",
        "\n",
        "When we get the gradients of our model, we have another structure of the same type, and it's possible to perform basic arithmetic on those structures to make the update step super simple:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-vNeypSRiC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in 1 ... epochs {\n",
        "    for i in 0 ..< (n-1)/bs {\n",
        "        let startIdx = i * bs\n",
        "        let endIdx = startIdx + bs\n",
        "        let xb = xTrain[startIdx..<endIdx]\n",
        "        let yb = yTrain[startIdx..<endIdx]\n",
        "        let (loss, grads) = model.valueWithGradient {\n",
        "            softmaxCrossEntropy(logits: $0(xb), labels: yb)\n",
        "        }\n",
        "        model.variables -= grads.scaled(by: lr)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptgnj9qARyWR",
        "colab_type": "text"
      },
      "source": [
        "Then we can use a S4TF optimizer to do the step for us (which doesn't win much just yet - but will be nice when we can use momentum, adam, etc). An optimizer takes a Model.AllDifferentiableVariables object and some gradients, and will perform the update."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POujM03nRvi_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let optimizer = SGD(for: model, learningRate: lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo5_b1A3R6sB",
        "colab_type": "text"
      },
      "source": [
        "Here's a handy function (thanks for Alexis Gallagher) to grab a batch of indices at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-UsqcDIR4M-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "//export\n",
        "public func batchedRanges(start:Int, end:Int, bs:Int) -> UnfoldSequence<Range<Int>,Int>\n",
        "{\n",
        "  return sequence(state: start) { (batchStart) -> Range<Int>? in\n",
        "    let remaining = end - batchStart\n",
        "    guard remaining > 0 else { return nil}\n",
        "    let currentBs = min(bs,remaining)\n",
        "    let batchEnd = batchStart.advanced(by: currentBs)\n",
        "    defer {  batchStart = batchEnd  }\n",
        "    return batchStart ..< batchEnd\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oguq1YUSB1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in 1 ... epochs{\n",
        "    for b in batchedRanges(start: 0, end: n, bs: bs) {\n",
        "        let (xb,yb) = (xTrain[b],yTrain[b])\n",
        "        let (loss, grads) = model.valueWithGradient {\n",
        "            softmaxCrossEntropy(logits: $0(xb), labels: yb)\n",
        "        }\n",
        "        optimizer.update(&model.variables, along: grads)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFoZOIc-SP8K",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Dataset\n",
        "\n",
        "We can create a swift Dataset from our arrays. It will automatically batch things for us:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svzYnnWSSNAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// export\n",
        "public struct DataBatch<Inputs: Differentiable & TensorGroup, Labels: TensorGroup>: TensorGroup {\n",
        "    public var xb: Inputs\n",
        "    public var yb: Labels\n",
        "    \n",
        "    public init(xb: Inputs, yb: Labels){ (self.xb,self.yb) = (xb,yb) }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJ3rbrabSSbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "d22e442f-fe2b-41af-e14c-e5f68e3a7fea"
      },
      "source": [
        "let trainDs = Dataset(elements:DataBatch(xb:xTrain, yb:yTrain)).batched(bs)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-08-18 01:13:51.357265: W tensorflow/core/framework/allocator.cc:107] Allocation of 188160000 exceeds 10% of system memory.\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "By5H2EsZSacu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in 1...epochs{\n",
        "    for batch in trainDs {\n",
        "        let (loss, grads) = model.valueWithGradient {\n",
        "            softmaxCrossEntropy(logits: $0(xb), labels: yb)\n",
        "        }\n",
        "        optimizer.update(&model.variables, along: grads)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSljM4mCSii0",
        "colab_type": "text"
      },
      "source": [
        "This Dataset can also do the shuffle for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc67WHxPShQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in 1...epochs{\n",
        "    for batch in trainDs.shuffled(sampleCount: yTrain.shape[0], randomSeed: 42){\n",
        "        let (loss, grads) = model.valueWithGradient {\n",
        "            softmaxCrossEntropy(logits: $0(xb), labels: yb)\n",
        "        }\n",
        "        optimizer.update(&model.variables, along: grads)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZTJxJJ5SqKq",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Training loop\n",
        "\n",
        "With everything before, we can now write a generic training loop. It needs two generic types: the optimizer (Opt) and the labels (Label):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUOQXvnMSoJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "public func train<Opt: Optimizer, Label:TensorGroup>(\n",
        "    _ model: inout Opt.Model,\n",
        "    on ds: Dataset<DataBatch<Opt.Model.Input, Label>>,\n",
        "    using opt: inout Opt,\n",
        "    lossFunc: @escaping @differentiable (Opt.Model.Output, @nondiff Label) -> Tensor<Opt.Scalar>\n",
        ") where Opt.Model: Layer,\n",
        "        Opt.Model.Input: TensorGroup,\n",
        "        Opt.Model.TangentVector == Opt.Model.AllDifferentiableVariables,\n",
        "        Opt.Scalar: TensorFlowFloatingPoint\n",
        "{\n",
        "    for batch in ds {\n",
        "        let (loss, 𝛁model) = model.valueWithGradient {\n",
        "            lossFunc($0(batch.xb), batch.yb)\n",
        "        }\n",
        "        opt.update(&model.variables, along: 𝛁model)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuW-4PlVSvOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var model = MyModel(nIn: m, nHid: nHid, nOut: Int(c))\n",
        "var optimizer = SGD(for: model, learningRate: lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiIO0B52S8fU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train(&model, on: trainDs, using: &optimizer, lossFunc: softmaxCrossEntropy)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1iELmt2S-vL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "de6f628a-3851-4eae-e21c-764e9b59eb9e"
      },
      "source": [
        "let preds = model(xValid)\n",
        "accuracy(preds, yValid)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8763\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK7YMUiPTC0L",
        "colab_type": "text"
      },
      "source": [
        "Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBSZ-BXNTBNd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "70baa807-b331-47e6-c54a-3fea292b773a"
      },
      "source": [
        "import NotebookExport\n",
        "let exporter = NotebookExport(Path.cwd/\"03_minibatch_training.ipynb\")\n",
        "print(exporter.export(usingPrefix: \"FastaiNotebook_\"))"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "success\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkfSeb0DTFRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}