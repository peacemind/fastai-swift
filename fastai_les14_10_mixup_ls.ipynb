{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fastai-les14-10-mixup-ls.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "swift",
      "display_name": "Swift"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZRlD4utdPuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "58e2ef71-cd4b-4189-f563-1c023bc9215f"
      },
      "source": [
        "%install-location $cwd/swift-install\n",
        "%install '.package(path: \"$cwd/FastaiNotebook_09_optimizer\")' FastaiNotebook_09_optimizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing packages:\n",
            "\t.package(path: \"/content/FastaiNotebook_09_optimizer\")\n",
            "\t\tFastaiNotebook_09_optimizer\n",
            "With SwiftPM flags: []\n",
            "Working in: /tmp/tmp0o0ipo4o/swift-install\n",
            "Updating https://github.com/mxcl/Path.swift\n",
            "Updating https://github.com/saeta/Just\n",
            "Updating https://github.com/latenitesoft/NotebookExport\n",
            "Completed resolution in 2.81s\n",
            "[1/15] Compiling FastaiNotebook_09_optimizer 00_load_data.swift\n",
            "[2/15] Compiling FastaiNotebook_09_optimizer 01_matmul.swift\n",
            "[3/15] Compiling FastaiNotebook_09_optimizer 01a_fastai_layers.swift\n",
            "[4/15] Compiling FastaiNotebook_09_optimizer 02_fully_connected.swift\n",
            "[5/15] Compiling FastaiNotebook_09_optimizer 02a_why_sqrt5.swift\n",
            "[6/15] Compiling FastaiNotebook_09_optimizer 03_minibatch_training.swift\n",
            "[7/15] Compiling FastaiNotebook_09_optimizer 04_callbacks.swift\n",
            "[8/15] Compiling FastaiNotebook_09_optimizer 05_anneal.swift\n",
            "[9/15] Compiling FastaiNotebook_09_optimizer 05b_early_stopping.swift\n",
            "[10/15] Compiling FastaiNotebook_09_optimizer 06_cuda.swift\n",
            "[11/15] Compiling FastaiNotebook_09_optimizer 07_batchnorm.swift\n",
            "[12/15] Compiling FastaiNotebook_09_optimizer 08_data_block.swift\n",
            "[13/15] Compiling FastaiNotebook_09_optimizer 08a_heterogeneous_dictionary.swift\n",
            "[14/15] Compiling FastaiNotebook_09_optimizer 09_optimizer.swift\n",
            "[15/16] Merging module FastaiNotebook_09_optimizer\n",
            "[16/17] Compiling jupyterInstalledPackages jupyterInstalledPackages.swift\n",
            "[17/18] Merging module jupyterInstalledPackages\n",
            "[18/18] Linking libjupyterInstalledPackages.so\n",
            "Initializing Swift...\n",
            "Installation complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqmlKsHQXMWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "// export\n",
        "import Path\n",
        "import TensorFlow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0gUoQQjXQ7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import FastaiNotebook_09_optimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaU28WyvXQ4M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed429708-2bec-42b7-d0ee-eb1c381d7f27"
      },
      "source": [
        "%include \"EnableIPythonDisplay.swift\"\n",
        "IPythonDisplay.shell.enable_matplotlib(\"inline\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('inline', 'module://ipykernel.pylab.backend_inline')\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWbjGwKNXZws",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Load data\n",
        "\n",
        "//TODO: switch to imagenette when possible to train\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxipYyqkXcoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "f6329eb5-e3eb-465f-9d0f-30afb7bd11fc"
      },
      "source": [
        "let data = mnistDataBunch(flat: true)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz...\n",
            "2019-08-23 21:24:40.868398: W tensorflow/core/framework/allocator.cc:107] Allocation of 188160000 exceeds 10% of system memory.\n",
            "2019-08-23 21:24:40.985066: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "2019-08-23 21:24:40.997541: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2019-08-23 21:24:40.997910: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2db0a80 executing computations on platform Host. Devices:\n",
            "2019-08-23 21:24:40.997973: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\n",
            "2019-08-23 21:24:41.047306: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\n",
            "2019-08-23 21:24:41.050210: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2019-08-23 21:24:41.050315: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: 232e6f7e4296\n",
            "2019-08-23 21:24:41.050348: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: 232e6f7e4296\n",
            "2019-08-23 21:24:41.050421: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 430.40.0\n",
            "2019-08-23 21:24:41.050467: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 418.67.0\n",
            "2019-08-23 21:24:41.050494: E tensorflow/stream_executor/cuda/cuda_diagnostics.cc:313] kernel version 418.67.0 does not match DSO version 430.40.0 -- cannot find working devices in this configuration\n",
            "2019-08-23 21:24:41.052963: W tensorflow/core/framework/allocator.cc:107] Allocation of 188160000 exceeds 10% of system memory.\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz...\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz...\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQNWVTgNXeSD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let (n,m) = (60000,784)\n",
        "let c = 10\n",
        "let nHid = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPBF1Y4RXgtU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func modelInit() -> BasicModel {return BasicModel(nIn: m, nHid: nHid, nOut: c)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jqe1eQOeXixb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let learner = Learner(data: data, lossFunc: softmaxCrossEntropy, optFunc: sgdOpt(lr: 0.1), modelInit: modelInit)\n",
        "let recorder = learner.makeDefaultDelegates(metrics: [accuracy])\n",
        "learner.delegates.append(learner.makeNormalize(mean: mnistStats.mean, std: mnistStats.std))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTIGXlxvXkrl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d6408aa2-1227-44bc-d052-040a779af96a"
      },
      "source": [
        "learner.fit(1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: [0.37816286, 0.9114]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJNdSaXNXnYi",
        "colab_type": "text"
      },
      "source": [
        "Mixup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XzaSctLXmhj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "//export\n",
        "extension RandomDistribution {\n",
        "    // Returns a batch of samples.\n",
        "    func next<G: RandomNumberGenerator>(\n",
        "        _ count: Int, using generator: inout G\n",
        "    ) -> [Sample] {\n",
        "        var result: [Sample] = []\n",
        "        for _ in 0..<count {\n",
        "            result.append(next(using: &generator))\n",
        "        }\n",
        "        return result\n",
        "    }\n",
        "\n",
        "    // Returns a batch of samples, using the global Threefry RNG.\n",
        "    func next(_ count: Int) -> [Sample] {\n",
        "        return next(count, using: &ThreefryRandomNumberGenerator.global)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGYDEjgoXtJh",
        "colab_type": "text"
      },
      "source": [
        "Mixup requires one-hot encoded targets since we don't have a loss function with no reduction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StiZ6A81XrQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "//export\n",
        "extension Learner {\n",
        "    public class MixupDelegate: Delegate {\n",
        "        private var distribution: BetaDistribution\n",
        "        \n",
        "        public init(alpha: Float = 0.4){\n",
        "            distribution = BetaDistribution(alpha: alpha, beta: alpha)\n",
        "        }\n",
        "        \n",
        "        override public func batchWillStart(learner: Learner) {\n",
        "            if let xb = learner.currentInput {\n",
        "                if let yb = learner.currentTarget as? Tensor<Float>{\n",
        "                    var lambda = Tensor<Float>(distribution.next(Int(yb.shape[0])))\n",
        "                    lambda = max(lambda, 1-lambda)\n",
        "                    let shuffle = Raw.randomShuffle(value: Tensor<Int32>(0..<Int32(yb.shape[0])))\n",
        "                    let xba = Raw.gather(params: xb, indices: shuffle)\n",
        "                    let yba = Raw.gather(params: yb, indices: shuffle)\n",
        "                    lambda = lambda.expandingShape(at: 1)\n",
        "                    learner.currentInput = lambda * xb + (1-lambda) * xba\n",
        "                    learner.currentTarget = (lambda * yb + (1-lambda) * yba) as? Label\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    public func makeMixupDelegate(alpha: Float = 0.4) -> MixupDelegate {\n",
        "        return MixupDelegate(alpha: alpha)\n",
        "    }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La8P0IIjXwgU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let (n,m) = (60000,784)\n",
        "let c = 10\n",
        "let nHid = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onL_iMXsXzlx",
        "colab_type": "text"
      },
      "source": [
        "We need to one-hot encode the targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukYz4zkKXyxS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var train1 = data.train.innerDs.map { DataBatch<TF,TF>(xb: $0.xb, \n",
        "                            yb: Raw.oneHot(indices: $0.yb, depth: TI(10), onValue: TF(1), offValue: TF(0))) }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFqQw2cmX2cM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "var valid1 = data.valid.innerDs.map { DataBatch<TF,TF>(xb: $0.xb, \n",
        "                            yb: Raw.oneHot(indices: $0.yb, depth: TI(10), onValue: TF(1), offValue: TF(0))) }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs622y6TX4hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let data1 = DataBunch(train: train1, valid: valid1, trainLen: data.train.dsCount, \n",
        "                  validLen: data.valid.dsCount, bs: data.train.bs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUb-rilZX6qr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func modelInit() -> BasicModel {return BasicModel(nIn: m, nHid: nHid, nOut: c)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8GkEVXIX8r0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "func accuracyFloat(_ out: TF, _ targ: TF) -> TF {\n",
        "    return TF(out.argmax(squeezingAxis: 1) .== targ.argmax(squeezingAxis: 1)).mean()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OetfUpu-X-iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let learner = Learner(data: data1, lossFunc: softmaxCrossEntropy, optFunc: sgdOpt(lr: 0.1), modelInit: modelInit)\n",
        "let recorder = learner.makeRecorder()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLmyg90oX_7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learner.delegates = [learner.makeTrainEvalDelegate(), learner.makeShowProgress(), \n",
        "                     learner.makeAvgMetric(metrics: [accuracyFloat]), recorder,\n",
        "                     learner.makeMixupDelegate(alpha: 0.2)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR6lyfynYBqS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d5f6e325-558e-4ff1-928f-57697dca340b"
      },
      "source": [
        "learner.fit(2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: [0.5435329, 0.9135]\n",
            "Epoch 1: [0.51660204, 0.9194]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "755INf_hYF95",
        "colab_type": "text"
      },
      "source": [
        "Labelsmoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c69le57XYEOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "//export\n",
        "@differentiable(wrt: out)\n",
        "public func labelSmoothingCrossEntropy(_ out: TF, _ targ: TI, ε: Float = 0.1) -> TF {\n",
        "    let c = out.shape[1]\n",
        "    let loss = softmaxCrossEntropy(logits: out, labels: targ)\n",
        "    let logPreds = logSoftmax(out)\n",
        "    return (1-ε) * loss - (ε / Float(c)) * logPreds.mean()\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHAFoV8AYJIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@differentiable(wrt: out)\n",
        "func lossFunc(_ out: TF, _ targ: TI) -> TF { return labelSmoothingCrossEntropy(out, targ, ε: 0.1) }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRgc34NlYLMp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "let learner = Learner(data: data, lossFunc: lossFunc, optFunc: sgdOpt(lr: 0.1), modelInit: modelInit)\n",
        "let recorder = learner.makeDefaultDelegates(metrics: [accuracy])\n",
        "learner.delegates.append(learner.makeNormalize(mean: mnistStats.mean, std: mnistStats.std))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-W-N0kTYNqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4ddaaf2b-2fd2-4ea7-88ac-cf8d7f09eafe"
      },
      "source": [
        "learner.fit(2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: [0.2978364, 0.9329]\n",
            "Epoch 1: [0.2847682, 0.94]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCeUNxSkYSvx",
        "colab_type": "text"
      },
      "source": [
        "Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieJOpxcmYQhJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "257cad33-782f-4e85-fa7d-fa6772452ea3"
      },
      "source": [
        "import NotebookExport\n",
        "let exporter = NotebookExport(Path.cwd/\"10_mixup_ls.ipynb\")\n",
        "print(exporter.export(usingPrefix: \"FastaiNotebook_\"))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "success\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VddalFKVYT8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}